# 进程调度源码分析

## 调度 为啥 怎么 意义

## O(N)调度

### 算法思想 

### 具体实现
``` c
asmlinkage void schedule(void)
{
	struct schedule_data * sched_data;
	struct task_struct *prev, *next, *p;
	struct list_head *tmp;
	int this_cpu, c;

	if (!current->active_mm) BUG();
need_resched_back:
	prev = current;
	this_cpu = prev->processor;

	if (in_interrupt())
		goto scheduling_in_interrupt;

	release_kernel_lock(prev, this_cpu);

	/* Do "administrative" work here while we don't hold any locks */
	if (softirq_active(this_cpu) & softirq_mask(this_cpu))
		goto handle_softirq;
handle_softirq_back:

	/*
	 * 'sched_data' is protected by the fact that we can run
	 * only one process per CPU.
	 */
	sched_data = & aligned_data[this_cpu].schedule_data;

	spin_lock_irq(&runqueue_lock);

	/* move an exhausted RR process to be last.. */
	if (prev->policy == SCHED_RR)
		goto move_rr_last;
move_rr_back:

	switch (prev->state) {
		case TASK_INTERRUPTIBLE:
			if (signal_pending(prev)) {
				prev->state = TASK_RUNNING;
				break;
			}
		default:
			del_from_runqueue(prev);
		case TASK_RUNNING:
	}
	prev->need_resched = 0;

	/*
	 * this is the scheduler proper:
	 */

repeat_schedule:
	/*
	 * Default process to select..
	 */
	next = idle_task(this_cpu);
	c = -1000;
	if (prev->state == TASK_RUNNING)
		goto still_running;

still_running_back:
	list_for_each(tmp, &runqueue_head) {
		p = list_entry(tmp, struct task_struct, run_list);
		if (can_schedule(p, this_cpu)) {
			int weight = goodness(p, this_cpu, prev->active_mm);
			if (weight > c)
				c = weight, next = p;
		}
	}

	/* Do we need to re-calculate counters? */
	if (!c)
		goto recalculate;
	/*
	 * from this point on nothing can prevent us from
	 * switching to the next task, save this fact in
	 * sched_data.
	 */
	sched_data->curr = next;
#ifdef CONFIG_SMP
 	next->has_cpu = 1;
	next->processor = this_cpu;
#endif
	spin_unlock_irq(&runqueue_lock);

	if (prev == next)
		goto same_process;

#ifdef CONFIG_SMP
 	/*
 	 * maintain the per-process 'last schedule' value.
 	 * (this has to be recalculated even if we reschedule to
 	 * the same process) Currently this is only used on SMP,
	 * and it's approximate, so we do not have to maintain
	 * it while holding the runqueue spinlock.
 	 */
 	sched_data->last_schedule = get_cycles();

	/*
	 * We drop the scheduler lock early (it's a global spinlock),
	 * thus we have to lock the previous process from getting
	 * rescheduled during switch_to().
	 */

#endif /* CONFIG_SMP */

	kstat.context_swtch++;
	/*
	 * there are 3 processes which are affected by a context switch:
	 *
	 * prev == .... ==> (last => next)
	 *
	 * It's the 'much more previous' 'prev' that is on next's stack,
	 * but prev is set to (the just run) 'last' process by switch_to().
	 * This might sound slightly confusing but makes tons of sense.
	 */
	prepare_to_switch();
	{
		struct mm_struct *mm = next->mm;
		struct mm_struct *oldmm = prev->active_mm;
		if (!mm) {
			if (next->active_mm) BUG();
			next->active_mm = oldmm;
			atomic_inc(&oldmm->mm_count);
			enter_lazy_tlb(oldmm, next, this_cpu);
		} else {
			if (next->active_mm != mm) BUG();
			switch_mm(oldmm, mm, next, this_cpu);
		}

		if (!prev->mm) {
			prev->active_mm = NULL;
			mmdrop(oldmm);
		}
	}

	/*
	 * This just switches the register state and the
	 * stack.
	 */
	switch_to(prev, next, prev);
	__schedule_tail(prev);

same_process:
	reacquire_kernel_lock(current);
	if (current->need_resched)
		goto need_resched_back;

	return;

recalculate:
	{
		struct task_struct *p;
		spin_unlock_irq(&runqueue_lock);
		read_lock(&tasklist_lock);
		for_each_task(p)
			p->counter = (p->counter >> 1) + NICE_TO_TICKS(p->nice);
		read_unlock(&tasklist_lock);
		spin_lock_irq(&runqueue_lock);
	}
	goto repeat_schedule;

still_running:
	c = goodness(prev, this_cpu, prev->active_mm);
	next = prev;
	goto still_running_back;

handle_softirq:
	do_softirq();
	goto handle_softirq_back;

move_rr_last:
	if (!prev->counter) {
		prev->counter = NICE_TO_TICKS(prev->nice);
		move_last_runqueue(prev);
	}
	goto move_rr_back;

scheduling_in_interrupt:
	printk("Scheduling in interrupt\n");
	BUG();
	return;
}
```


​	细节处理

​	
## O(1)调度
### 算法思想 

在上面的算法中仍存在一些问题

1、单就绪队列问题，而时间片耗完的进程仍存在于队列中，选择新进程时所需时间也变长

2、多处理器问题，多处理器上的进程放在一个就绪队列中，使其变为临界资源

3、内核态不可抢占问题，当有非常紧迫的任务来时，也需要等待进入内核态的进程返回

把原先的就绪队列的单个链表变成了多个链表，每一个优先级的进程被挂入到不同的链表里面，系统中所有的就绪进程首先经过负载均衡模块挂入各个CPU的就绪队列上，然后由主调度器和周期性调度器驱动该CPU上的调度行为,

![Alt text](image-1.png)
**runqueue结构**

每个CPU都需要维护一个 runqueue 结构，runqueue 结构主要维护任务调度相关的信息，比如优先队列、调度次数、CPU负载信息等。
``` c
struct runqueue {
    spinlock_t lock;
    unsigned long nr_running,
                  nr_switches,
                  expired_timestamp,
                  nr_uninterruptible;
    task_t *curr, *idle;
    struct mm_struct *prev_mm;
    prio_array_t *active, *expired, arrays[2];  //prio_array_t即为后文的prio_array
    int prev_cpu_load[NR_CPUS];
    task_t *migration_thread;
    struct list_head migration_queue;
    atomic_t nr_iowait;
};
```
`active`和`expired`指针类型为 `prio_array`，其分别指向array[0]、array[1]，其中active代表可以调度的任务队列，而expired字段代表时间片已经用完的任务队列，当active中的任务时间片用完，那么就会被移动到expired中。

![Alt text](image-2.png)


**优先级数组的结构**

```c
struct prio_array
{
	unsigned int nr_active;
	unsigned long bitmap[BITMAP_SIZE];
	struct list_head queue[MAX_PRIO];
};
```

![Alt text](image.png)
队列成员中有140个分别表示各优先级的链表头，其中100-139是普通进程的优先级，其余是实时进程的优先级，其被分开来进行管理，不同优先级的进程被挂入不同的链表中，`bitmap`用来表示各个优先级进程链表是空还是非空。`nr_avtive`是表示总任务数，当进行调度时，通过位图找到非空进程队列，即可以常数的时间级找到要调度的进程

![Alt text](image-5.png)

**核心调度算法**
```c
array = rq->active;	
idx = sched_find_first_bit(array->bitmap);
queue = array->queue + idx;
next = list_entry(queue->next, task_t, run_list);
```

算法的核心思想，去从runqueue的active队列中的bitmap找到一个下标，这个下标就是对应的优先级，然后获取到对应优先级的链表，然后从中获取一个next进程。后面的操作就是执行进程切换，调度了

调度器删除了全局runqueue的spin lock，而是把这个spin lock放入到per-CPU runqueue数据结构中（rq->lock），通过把一个大锁细分成小锁，可以大大降低调度延迟，提升系统响应时间。这种方法在内核中经常使用，是一个比较通用的性能优化方法


**时钟中断**

时钟中断是由硬件触发的，可以通过编程来设置其频率，Linux内核一般设置为每秒产生100 ~ 1000次。时钟中断会触发调用 scheduler_tick() 内核函数，其主要工作是：减少进程的可运行时间片，如果时间片用完，那么把进程从 active 队列移动到 expired 队列中。代码如下：

```c
if (!--p->time_slice) {
	dequeue_task(p, rq->active);
	set_tsk_need_resched(p);
	p->prio = effective_prio(p);
	p->time_slice = task_timeslice(p);
	p->first_time_slice = 0;
 
	if (!rq->expired_timestamp)
		rq->expired_timestamp = jiffies;
	if (!TASK_INTERACTIVE(p) || EXPIRED_STARVING(rq)) {//如果是交互式进程或者expired队列饥饿
		enqueue_task(p, rq->expired);
		if (p->static_prio < rq->best_expired_prio)
			rq->best_expired_prio = p->static_prio;
	} else
		enqueue_task(p, rq->active);
}
```
缺省时间片的计算是通过task_timeslice完成的，在tick到来的时候，当前task的时间片会递减（--p->time_slice），当时间片等于0的时候，会将该task从active优先级列表中摘下，设定resched标记，并且重置时间片


当时间片耗完时，则需要将进程从active队列中移除掉，需要设置需要重新调度的标志TIF_NEED_RESCHED。同时还需要重新计算此进程的优先级，时间片。而O(1)调度器算法比O(n)不是那么的粗暴，还需要判断是否是交互式进程，或者此进程是不是饥饿进程，如果是则将又添加到active队列中，否则添加到expried队列。

其中为了保证交互式/实时进程的响应时间，当此类进程时间片为0时，重置其时间片并重新插入active数组，但其不能一直呆在active数组中，会导致expired中的数饥饿，所有当其占用CPU时间达到一个固定值时，将其转移到expired中，当active中已经没有任务可以运行，就把 expired与active调转。


### 具体实现 

```c
asmlinkage void schedule(void)//asmlinkage标志指示编译器使用汇编语法的调用约定
{
	task_t *prev, *next;	//prve表示调度之间的进程，next表示调度之后的进程
	runqueue_t *rq; 		//存储就绪队列的结构 
	prio_array_t *array;	//prio_array结构 存储进程队列
	struct list_head *queue;//链表
	unsigned long long now;	//当前时间
	unsigned long run_time;	//进程运行时间
	int idx;				//索引值

	//检查当前进程是否为TASK_DEAD终止态或TASK_ZOMBIE僵尸态
	//likely 用于提示编译器这是一个常见情况，可以优化代码执行。
	if (likely(!(current->state & (TASK_DEAD | TASK_ZOMBIE)))) {
		if (unlikely(in_atomic())) {	//如果处在原子操作
			printk(KERN_ERR "bad: scheduling while atomic!\n");
			dump_stack();//记录当前的调用栈信息 帮助开发人员识别问题
		}
	}

//先禁止抢占，再初始化一些变量,需要访问任务的运行队列
need_resched:
	preempt_disable(); //禁用内核的抢占
	prev = current; 	//存储当前进程
	rq = this_rq();		//获取当前运行队列的指针

	release_kernel_lock(prev); 	//释放当前任务所占用的内核锁
	now = sched_clock();		//获取当前时间
	//检查当前任务的运行时间是否小于NS_MAX_SLEEP_AVG，取二者的小值
	if (likely(now - prev->timestamp < NS_MAX_SLEEP_AVG))
		run_time = now - prev->timestamp;
	else
		run_time = NS_MAX_SLEEP_AVG;

	//检查当前任务是否有高优先级的信用
	if (HIGH_CREDIT(prev))//对有较长睡眠时间的进程，进行一定奖励
		run_time /= (CURRENT_BONUS(prev) ? : 1);//将 run_time 除以当前任务的奖励，否则除以1

    //在开始寻找可运行进程之前，需要关中断并获得保护运行队列的自旋锁
	spin_lock_irq(&rq->lock); //获取运行队列的锁，以确保对运行队列的访问是原子的，不会被中断。

	if (unlikely(preempt_count() & PREEMPT_ACTIVE)) //用于检查当前是否处于抢占活动状态
		goto pick_next_task; //直接跳转到选择下一进程

	switch (prev->state) {//判断先前进程的状态
	case TASK_INTERRUPTIBLE://用当前处于可抢占活动状态
		if (unlikely(signal_pending(prev))) { //检查当前任务是否有挂起的信号
			prev->state = TASK_RUNNING;	//将当前任务的状态设置为TASK_RUNNING
			break;
		}
	default:
		deactivate_task(prev, rq);//不是可中断等待状态或没有挂起的信号，将当前任务从运行队列中移除。
		prev->nvcsw++;//增加当前任务的非抢占式上下文切换计数
		break;
	case TASK_RUNNING:
		prev->nivcsw++;//增加当前任务的非抢占式上下文切换计数
	}
pick_next_task:
	if (unlikely(!rq->nr_running)) {//检查当前运行队列中是否没有正在运行的任务
#ifdef CONFIG_SMP //是否启用了多处理器（SMP）支持
		load_balance(rq, 1, cpu_to_node_mask(smp_processor_id()));//进行负载均衡操作
		if (rq->nr_running)
			goto pick_next_task;
#endif
		next = rq->idle;//如果没有需要运行的任务，将 next 指向运行队列的空闲任务
		//expired_timestamp表示当前队列中，过期队列中最老进程被插入过期队列的时间。
		rq->expired_timestamp = 0;//将运行队列的 expired_timestamp 设置为0。
		goto switch_tasks;//跳转到切换模块
	}

	array = rq->active;//将array赋为active队列
	if (unlikely(!array->nr_active)) {//检查array中是否没有等待运行的任务
		//交换active与expired指针,实现结构调转
		rq->active = rq->expired;
		rq->expired = array;
		array = rq->active;
		rq->expired_timestamp = 0;
	}

	idx = sched_find_first_bit(array->bitmap);//在位图中查找下一个要调度的索引
	queue = array->queue + idx;//根据索引idx获取任务队列中的相应队列头节点
	next = list_entry(queue->next, task_t, run_list);//获取下一个要运行的任务
	/*activated表达的是从什么状态被唤醒
	0，进程处于TASK_RUNNING状态；
	1，进程处于TASK_INTERRUPTIBLE或者TASK_STOPPED状态，常见例子就是被信号唤醒
	2，进程处于TASK_INTERRUPTIBLE或者TASK_STOPPED状态，常见例子就是IO中断；
	-1，表示从UNINTERRUPTIBLE状态被唤醒。
	*/
	if (next->activated > 0) {//检查下一个任务的激活状态是否大于0
		unsigned long long delta = now - next->timestamp;//计算当前时间 now 与下一个任务的时间戳之间的时间差

		if (next->activated == 1)//检查下一个任务的激活状态是否等于1
			delta = delta * (ON_RUNQUEUE_WEIGHT * 128 / 100) / 128;//根据特定权重和比例，调整 delta 的值

		array = next->array;//指向下一进程的prio_array结构
		dequeue_task(next, array);//将下一个任务从数组中的队列中移除
		recalc_task_prio(next, next->timestamp + delta);//重新计算下一个任务的优先级，考虑时间差 delta
		enqueue_task(next, array);//将下一个任务重新加入到队列中。
	}
	next->activated = 0;//将下一个任务的激活状态设置为0，表示它不再激活
switch_tasks:
	prefetch(next);//预取下一个任务 next 的数据。预取是一种优化技术，用于提前将数据加载到高速缓存，以提高程序执行的效率。
	clear_tsk_need_resched(prev);//清除前一个任务 prev 的重新调度标志
	RCU_qsctr(task_cpu(prev))++;//用于跟踪前一个任务的统计信息的操作，通常与 RCU（Read-Copy-Update）机制有关

	prev->sleep_avg -= run_time;//减去前一个任务的 sleep_avg 值，这表示前一个任务经过了一段时间的运行，其睡眠平均值会相应减少。
	if ((long)prev->sleep_avg <= 0){//如果前一个任务的 sleep_avg 小于等于0，将其设置为0
		prev->sleep_avg = 0;
		if (!(HIGH_CREDIT(prev) || LOW_CREDIT(prev)))//检查前一个任务是否既不是高优先级任务也不是低优先级任务。
			prev->interactive_credit--;//减少前一个任务的交互式信用
	}
	prev->timestamp = now;//更新前一个任务的时间戳，使其与当前时间 now 同步

	if (likely(prev != next)) {//检查前一个任务 prev 是否与下一个任务 next 不同
		next->timestamp = now;//将下一个任务 next 的时间戳更新为当前时间 now
		rq->nr_switches++;//增加运行队列 rq 的切换次数计数，表示进行了一次任务切换
		rq->curr = next;//将运行队列 rq 的当前任务指针更新为下一个任务 next，表示下一个任务将成为当前任务。

		prepare_arch_switch(rq, next);//执行体系结构相关的任务切换准备操作
		prev = context_switch(rq, prev, next);//执行任务切换操作，将前一个任务 prev 切换到下一个任务 next。这是任务切换的核心操作
		barrier();//为了防止编译器对代码优化时，改变代码的先后顺序

		finish_task_switch(prev);//完成任务切换，通常执行一些收尾工作
	} else
		spin_unlock_irq(&rq->lock);//如果前一个任务与下一个任务相同（即没有进行任务切换），则解锁运行队列 rq 的锁。

	reacquire_kernel_lock(current);//重新获取内核锁。
	preempt_enable_no_resched();//启用抢占
	if (test_thread_flag(TIF_NEED_RESCHED))//检查是否需要重新调度任务
		goto need_resched;//跳转到 need_resched 
}
```

context_switch(rq, prev, next);

```c
//context_switch - 切换到新的虚存和新线程的寄存器状态。
static inline task_t * context_switch(runqueue_t *rq, task_t *prev, task_t *next)//rq表示运行队列 prev表示前一个进程 next表示下一个进程
{
	struct mm_struct *mm = next->mm;//下一个线程的内存管理结构
	struct mm_struct *oldmm = prev->active_mm;//前一个线程的活动内存管理结构

	if (unlikely(!mm)) {//检查下一个线程的 mm 是否为空 即为内核线程
 		next->active_mm = oldmm;//前一个线程的oldmm赋给下一个线程的active_mm
 		atomic_inc(&oldmm->mm_count);//增加 oldmm 的引用计数，表示它仍然在使用
 		enter_lazy_tlb(oldmm, next);//调用 enter_lazy_tlb 来更新内存页表的信息，以确保 TLB不包含旧线程的无效信息
 	} else//用户线程
 		switch_mm(oldmm, mm, next);//执行内存管理的切换操作

 	if (unlikely(!prev->mm)) {//如果前一个线程没有mm
  		prev->active_mm = NULL;//将前一个线程的 active_mm 设置为 NULL
 		WARN_ON(rq->prev_mm);
 		rq->prev_mm = oldmm;
 	}

 	/* Here we just switch the register state and the stack. */
 	switch_to(prev, next, prev);//执行线程的寄存器状态和栈的切换，将控制权从前一个线程切换到下一个线程。

 	return prev;
}
```



## 算法对比

- O(1)调度器的引入主要是为了解决O(n)调度器的不足

- O(1)调度器在赏罚机制上比O(n)调度器考虑的因素比较多，不再时像O(1)那样直接考时间片的大小来调度

- O(n)和O(1)调度算法上核心还是通过判断一个进程的行为，比如睡眠进程赏罚机制，睡眠来增大优先级，增大时间片的机制来获取更多的运行时间。

- O(1)中加了很多必要的判断，各种情况的考虑

  

## 总结和感悟
在本次学习中，由于代码繁多，在面对代码时有些不知从何入手，阅读源码后发现引出了大量的知识体系，例如锁、奖励机制等，由于体量庞大，只看重了核心代码部分，让我体会到内核知识体系的庞大与自己的不足，我们需要在平时的学习中不断积累，构建起自己的知识体系和框架，将知识前后贯通起来，才能真正理解其代码的优越之处。